\documentclass{article}

\usepackage{units, amsmath}

\newcommand{\mGamma}{\mathrm{\Gamma}}

\begin{document}

\section{Model}
\begin{equation} 
Y_{gvi} \stackrel{ind}{\sim} NB\left(e^{\mu_{gv}+\gamma_{vi}},e^{\psi_g}\right), 
\label{e:data}
\end{equation}
with probability mass function 
\[ p(y_{gvi}|\mu_{g},\gamma_{vi},\psi_g) =\frac{\mGamma(e^{\psi_g})}{y_{gvi}!\mathrm{\Gamma(e^{\psi_g})}}  p_{gv}^{y_{gvi}}(1-p_{gv})^{e^{\psi_g}} \] 
where $\mu_g = (\mu_{g1},\mu_{g2},\mu_{g3})$ and 
\[ p_{gv} = \frac{e^{\mu_{gv}+\gamma_{vi}}}{e^{\psi_g}+e^{\mu_{gv}+\gamma_{vi}}}. \]
This parameterization of the negative binomial has 
\[ E[Y_{gvi}] = \eta_{gvi} =e^{\mu_{gv}+\gamma_{vi}} \quad \mbox{and} \quad V[Y_{gvi}] = \eta_{gvi} + \eta_{gvi}^2/e^{\psi_g}. \]
Let $y_{g} = (y_{g11},\ldots,y_{g1n_1},y_{g21},\ldots,y_{g2n_2},y_{g31},\ldots,y_{g3n_3})$, then 
\[ 
p(y_g|\mu_{gv} ,\gamma_{vi}, \psi_g) = \prod_{v=1}^3 \prod_{i=1}^{n_v} p(y_{gvi}|\mu_{g},\gamma_{vi},\psi_g) 
\] 

\subsection{Reparameterization}

Rather than using a parameterization for the variety specific means, we reparameterize for the purpose of constructing a hierarhical model that performs appropriate shrinkage. Let 

\[ \phi_g = \frac{\mu_{g1}+\mu_{g2}}{2}, \quad 
\alpha_g = \frac{\mu_{g1}-\mu_{g2}}{2}, \quad \mbox{and} \quad
\delta_g = \phi_g-\mu_{g3}. \]
So, 
\[ \theta_g = (\phi_g,\alpha_g,\delta_g,\psi_g)^\top = T \mu_g = 
\left[ \begin{array}{cccc}
\nicefrac{1}{2} & \nicefrac{1}{2} & 0 & 0 \\
\nicefrac{1}{2} & -\nicefrac{1}{2} & 0 & 0\\
\nicefrac{1}{2} & \nicefrac{1}{2} & -1 & 0\\
0 & 0 & 0 & 1\\
\end{array}\right] \left[ \begin{array}{c}
\mu_{g1} \\ \mu_{g2} \\ \mu_{g3} \\ \psi_g 
\end{array} \right]
\]
We assume the distribution $\theta_g \sim p(\theta_g|\pi)$. 


\subsection{Observed Fisher information}

Let $\mathcal{I}(\mu_g)$ be the Fisher information for $\mu_g$, then 
\begin{align*}
\log p(y|\mu_g) 
&= \sum_{v=1}^3 \sum_{i=1}^{n_v} \log \mGamma(e^{\psi_g}+y_{gvi}) - \log(y_{gvi}!) -\mGamma(e^{\psi_g}) + y_{gvi}\log(p_{gv}) + e^{\psi_g} \log(1-p_{gv}) \\
\frac{\partial}{\partial \mu_{gv}} \log p(y|\mu_g)  
&= \sum_{v=1}^3 \sum_{i=1}^{n_v} \frac{y_{gvi}}{p_{gv}} \frac{\partial p_{gv}}{\partial \mu_{gv}} - \frac{e^{\psi_g}}{1-p_{gv}}  \frac{\partial p_{gv}}{\partial \mu_{gv}}  \\
&= \sum_{v=1}^3 \sum_{i=1}^{n_v} \frac{y_{gvi}}{p_{gv}} \frac{\partial p_{gv}}{\partial \mu_{gv}} - \frac{e^{\psi_g}}{1-p_{gv}}  \frac{\partial p_{gv}}{\partial \mu_{gv}}  \\
%
%
%
%
%
%\frac{\partial}{\partial \mu_{g1}}  \log p(y|\mu_g)  
%&= \sum_{v=1}^3 \sum_{i=1}^{n_v} \nabla \left(\log \mGamma(e^{\psi_g}+y_{gvi}) - \log(y_{gvi}!) -\mGamma(e^{\psi_g})  + y_{gvi}\log(p_{gv}) + e^{\psi_g} \log(1-p_{gv}) \right) \\
\end{align*}


\subsection{Normal approximation}

We would like to approximate the conditional 
\[ p(\theta_g| y,\pi) \propto p(y|\theta_g,\pi) = \prod_{v=1}^V \prod_{i=1}^{n_v} NB(y_{gvi}; \]



\section{Method of moments}

\begin{align*}
E[y_{gvi}|\pi] &= E[e^{\mu_{gv}|\pi] \approx 
\end{align*}

\end{document}
