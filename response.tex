\documentclass{article}

\usepackage{fullpage}
\usepackage{color}

\usepackage[parfill]{parskip}

\newcommand{\comment}[1]{\textit{#1}}
\newcommand{\response}[1]{#1}
\newcommand{\todo}[1]{{\color{red} #1}}

\begin{document}

\response{We thank the AE and two reviewers for their comments which dramatically improved the manuscript.}

Associate Editor comments:

\comment{The proposed model appears to be an extension of Ji et al. (2014) albeit with a differently specified likelihood function (negative binomial or Poisson-gamma) as perceived to be more appropriate for count data relative to the Gaussian likelihood function pursued in Ji et al. (2014). Both reviewers indicate that they are little underwhelmed by the performance of your proposed procedure relative to some of the existing methods that you compare against (i.e., ShrinkBayes, edgeR and baySeq).  Furthermore, they seem somewhat concerned about an ‘apples vs. oranges’ types of comparisons since the proposed hypothesis testing strategy in the proposed method is really not an option in the other methods.}

\response{We have assessed the Ji et al. approach and included it in Sections 3.2 and 3.3. Although the Ji et al.\ approach performed better than edgeR and baySeq, its performance was considerably worse than the performance of the methods we proposed.  Regarding the `apples vs.\ oranges comparison', we agree that the proposed hypothesis testing strategy is not available in other methods.  This was part of the motivation for developing our methods.  Our simulations show that doing the best we know how to do with existing methods is worse than doing what we proposed.  We think the comparison is relevant and answers a question that some readers would have raised had we not included methods like edgeR and baySeq in our simulation.}

\comment{Perhaps a reference to the promise of allele specific expression analyses (Discussion section) for inferring upon gene-expression heterosis might be useful to point readers into other directions with this work (Bell et al., 2013; Wei and Wang, 2013).}

\response{Thanks for pointing out these papers.  We have added a new concluding paragraph to the paper that cites the papers you mentioned as well as two others.}

\comment{I realize that Ji et al.’s (2014) work was intended for microarray data, or more specifically Gaussian likelihoods, but there has been some work that suggests that Gaussian likelihood specifications in MAANOVA may, oddly enough, have better properties for the analysis of RNA-seq data than more popular methods specifically intended for count data (edgeR and DESeq).  See Reeb and Steibel (2013) and also comments from one reviewer along these lines.  Since Ji et al.’s work also derives from ISU, have you assessed its performance relative to your proposed method on RNA-seq data?}

\response{We have included Ji et al.'s work as another alternative method, see Sections 3.2 and 3.3.} 

\comment{One seemingly glaring omission from this work is any comparative assessment of the proposed versus other methods (e.g. ShrinkBayes) on the actual maize dataset in Section 4.  Why is that missing? The comments made by one reviewer regarding a relative assessment of computing time relative to the other methods deserves attention.}

\response{We have added a comparison of the computing time required for each method in Section 4 of the revised manuscript. We have also added a comparison of edgeR estimates to eBayes (Laplace) in Figure 3 which show shrinkage for half-parental differences and hybrid effects.}

\response{Added in Section 4. The bottom line is edgeR takes seconds, Ji et al. takes minutes, the other methods take hours.}

\comment{Page 1.  I was instructed that heterosis is merely characterized by the hybrid performance not being equal to the average of the two parental lines.  So in your very first sentence, I might write “Heterosis, or hybrid vigor, occurs when hybrid progeny display phenotypes that are superior to the average phenotypes of their parents.” i.e., I might be only interested in the $\delta_g$’s. However, your later characterization of heterosis is really something called overdominance to me…where the hybrid performance exceeds the performance of either parent.  I wonder if you could then be more specific in your definitions in your first sentence…and also in your third sentence in this particular paragraph. lines 48-59.  Perhaps this was already captured well in the Ji et al. (2014) paper but why not simply test heterosis as the difference between the hybrid and the average parental performance (i.e. $\mu_3 - 0.5 \mu_1 - 0.5 \mu_2$).  Again, I think your issue pertains really to an overdominance test of some sort.}

\response{Many publications mentioning heterosis do not define it clearly.  For example, the 2013 {\em Nature Reviews Genetics} paper by Chen that we now cite in our revised manuscript states the following definition: ``Heterosis (Also known as hybrid vigour).  When hybrids display increased levels of growth, survival or fitness relative to their parents.''  Like Chen, some other author present heterosis as synonymous with hybrid vigor, and then go on to describe hybrid vigor as the phenomenon in which the hybrid outperforms the parents.  It may not be so clear what ``outperforms the parents'' means, but the idea behind hybrid vigor and the reason it is of such interest (particularly in maize) and so useful is that the hybrid is better than {\bf both parents}, not simply better than the average.  That said, we do agree with your definition of heterosis.  We originally wrote that first sentence so that it would be true regardless of which definition of heterosis one takes.  We were saying that heterosis occurs when hybrid vigor occurs.  The reverse is not necessarily so, and we did not claim it to be in that first sentence.  However, we acknowledge that our first sentence was misleading because most readers would naturally take the sentence for a definition.  Furthermore, for simplicity, we did start using ``heterosis'' as a synonym for the situation where the hybrid mean expression is more extreme than both parents.  That is really what we are interested in because the phenotypic traits we see in maize have this pattern, so it is only natural to seek genes whose expression has this same pattern.  In the revised manuscript, we have been more careful with terminology.  We have defined heterosis to be a difference between the hybrid mean and the average of the parental means.  We have also introduced a new term (extreme heterosis, EH) to specify the situation where the hybrid mean is more extreme than both parental means.  We continue to use low-parent heterosis (LPH) and high-parent heterosis (HPH) to distinguish the two types of EH.  We also explain in the manuscript why we prefer the LPH/HPH terminology to underdominance/overdominance.  In our experience, these latter terms are used to describe the ``gene action'' at a single locus with respect to some quantitative trait.  We can't asses the action of any locus on any of our expression traits in data from inbred and hybrid crosses.}

\comment{Page 2 line 35.  “We CONSIDER an…”}

\response{We fixed the error.  Thanks for catching this.}

\comment{Page 3 Line 7.  I don’t it is sufficient to mention the statistical software “Stan”.  Please provide a suitable description and citation.}

\response{We agree and have added the appropriate citation.}

\comment{Page 3 Line 26.  There are several ways to construct a Poisson-gamma distribution, all leading to different specifications of the relationship between the mean and variance of a negative binomial.  I apologize for the admittedly vain self-citation but there is one specification, for example, that specifies the variance to be a linear function of the mean of a negative binomial…see Equation 2.12b in  Tempelman and Gianola (1996).  I guess I’m not sure why most RNA-seq data analysts gravitate to a specification where the variance is specified to be linear and quadratic function of the mean as you do here.}

\response{You have raised in interesting point.  If $y_i|\lambda_i$ is Poisson with mean $\lambda_i$, and $\lambda_i$ is ${\rm gamma}(\alpha_i,\beta)$ for all $i=1,\ldots, n$, then (for all $i$) the marginal distribution of $y_i$ is negative binomial with mean $\mu_i$ and variance $\phi\mu_i$, where $\mu_i=\alpha_i\beta$ and $\phi=1+\beta$.  Thus, if we assume the $\beta$ parameter is constant across observations, we have a linear mean-variance relationship.  On the other hand, if $y_i|\lambda_i$ is Poisson with mean $\lambda_i$, and $\lambda_i$ is ${\rm gamma}(\alpha,\beta_i)$ for all $i=1,\ldots, n$, then (for all $i$) the marginal distribution of $y_i$ is negative binomial with mean $\mu_i$ and variance $\mu_i+\phi\mu_i^2$, where $\mu_i=\alpha\beta_i$ and $\phi=1/\alpha$.  Thus, if we assume the $\alpha$ parameter is constant across observations, we have a quadratic mean-variance relationship.  Past research suggests that RNA-seq data that includes biological (rather than only technical) variation tends to exhibit a quadratic mean-variance relationship.  Thus, we have focused on the latter type of negative binomial model specification.  It is conceivable that the linear mean-variance relationship could be appropriate for some subset of genes in an RNA-seq dataset.  That is an interesting model selection question, but one that we think should be left for future work focused specifically on this issue. }

\comment{Page 3. Bottom.  Shouldn’t you at least provide a justification when one would use a normal prior and when one would or should use a Laplace prior?}

\response{We have assessed the use of normal distributions see Section 3.3 and also provided rationale for why Laplace distributions would be expected to perform better in this scenario at the end of Section 2.1. Our simulation results in Figure 2 show that our Laplace model specification is preferred over the normal model specification.}

\comment{Page 4, bottom half.  The strategy described here, also somewhat attested to by a reviewer, is a little disconcerting with respect to the “double estimation” of gene-specific parameters…first to estimate they hyperparameters and then again conditioned on the estimates of these hyperparameters.  Perhaps you should characterize that these second-stage gene-specific estimates are shrunk relative to those estimates used to estimate the hyperparameters and that they then have lead to predictions with better properties?  Ideally, I would have liked to see these hyperparameters be also formally estimated together with the gene specific parameters within one MCMC analyses…authors should address why they didn’t do this.}

\response{We have added a paragraph to the beginning of Section 2.2 to share our experience with a fully MCMC analysis which took too long and had poor mixing. We have added a new Figure 3, which shows that the second-stage gene-specific estimates are shrunk relative to the original edgeR estimates.}

\comment{Page 5, lines 37-47.  Since you’re doing MCMC, why not simply tabulate the number of times samples of $\mu_3$ exceeds either $\mu_1$ or $\mu_2$….and/or the number of times that $\mu_3$ is less than $\mu_1$ or $\mu_2$.  I suspect that what your test is really doing….in which case it might be useful to explicitly state this equivalence as such.}

\response{Yes, that is what the test is doing. We have now stated the equivalence for both LPH and HPH, e.g. for LPH: $\delta_g < -|\alpha_g|$ is equivalent to $\mu_{g3} < \min(\mu_{g1},\mu_{g2})$.}

\comment{Page 6, top.  Is it possible then to assess your proposed method using Laplace versus normal priors to assess if that seems to be contributing to any differences between ShrinkBayes and your proposed method?  Maybe that is the real reason for the small improvements?...., and not the differences in sophistication of the constructed statistical tests?}

\response{We have now assessed the use of normal distributions. The results in Section 3.3 and Figure 2 show that there is an advantage to using Laplace distributions instead of normals.  Our eBayes implementation of our model performs quite similarly to our ShrinkBayes implementation of our model.}

\comment{Page 7, line 15.  Why delete the low counts?  Data quality issues?}

\response{ShrinkBayes failed for us when too many zeros were present. We do not believe the comparison of other methods would change if we did not remove genes with low counts.  In practice, it is common to remove low count genes from RNA-seq datasets prior to analysis because these genes contain little information about differential expression and lead to computational difficulties for some methods. With that being said, we did not remove any genes from the real data analysis.}

\comment{Page 7, lines 17-22.  Can you provide us any information on how well the hyperparameters were estimated based on your empirical Bayes strategy?}

\response{Since we did not simulate from the hierarchical portion of the model, there are no true values of the hyperparameters to compare against. We tried to get at this question by calculating means and standard deviations of the true values for the gene-specific parameters in each simulation. Table \ref{t:hyperparameter} shows root mean squared error (RMSE) of the estimated hyperparameters. Because each simulation has a different value of the hyperparameters (due to different genes randomly being included), the RMSEs are hard to interpret. For this reason, we did not include this table in the manuscript because we did not believe it added much value. }

\input{include/rmse}

\newpage
\comment{Page 8, line 37.  It is not obvious to me why $H_g2*$ (are the two parents the same?) is a necessary component of a heterosis (overdominance) test!?}

\response{Yes, that is the hypothesis that the two parents are the same, but the hybrid is different. It is not necessary, but it is sufficient. If parental expressions are the same and the hybrid is not, then the hybrid must be exhibiting either LPH or HPH.}

\comment{Page 9, lines 23-25.  In tandem with another reviewer’s comments, the real question is why?  Is it because of the suboptimality of the test that you contrived for ShrinkBayesA?}

\response{In Section 3.3, we highlighted the differences between ShrinkBayes and the eBayes approaches, but do not try to specifically state which difference is the cause.}

\comment{Page 10, Line 29.  Don’t you mean “nadir” rather than peak?}

\response{No, although we do mean ridge rather than peak, i.e. there are many genes with effect size of zero and probabilities below 0.5, and have updated the manuscript accordingly.}

\comment{Page 11 line 39.  Is it really “independence” or nearly non-identifiability that is the issue?}

\response{We're sorry, but we don't understand this comment. We believe all the parameters in the model are identified and therefore are not sure what non-identifiability is being referenced.}

\comment{Page 11 last paragraph.  So this then begs an assessment of how good/poor these hyperparameter estimates were.}

\response{See discussion above and Table \ref{t:hyperparameter}.}

\comment{Page 11 last line “ASYMPTOTIC”}

\response{Fixed.}

Reviewer \#1

\comment{The authors develop a hierarchical negative binomial model for drawing inferences from a composite null hypothesis, that tests gene expression heterosis. Simulations are performed to describe the performance of this new method along with a data analysis demonstrating an application to real data. This manuscript represents a well-conceived and executed methodological development in the statistical analysis of RNA-Seq gene expression data. However, the performance of the new method is underwhelming compared to existing methods, tempering my enthusiasm for the likely impact of this paper.}

\response{We assume that you mean the improvement compared to existing methods is underwhelming. To more accurately address the improvement, we calculated percentage improvement in AUC which ranges from 20\% to 100\% and discuss these in Section 3.3.}

\comment{(1) In the simulations, the authors should also compare the eBayes method to the method of Ji et al. (2014). Although developed for continuous microarray data, the authors could apply a simple transformation to the count data in order to make them continuous. I would be curious to know whether the eBayes method out-performs the method of Ji et al. (2014) on the transformed data.}

\response{We have assessed the approach of Ji et al. on transformed data, see Sections 3.2 and 3.3. The bottom line is that it doesn't perform as well as the methods based on our hierarchical negative-binomial model.}

\comment{(2) The authors should provide more details on the computational price of the eBayes method? How long (in comparison to edgeR, baySeq, ShrinkBayes) did the eBayes method take to run? Are these methods comparable in terms of computational cost?}

\response{Added in Section 4. The bottom line is edgeR takes seconds, Ji et al. takes minutes, the other methods take hours.}

\comment{(3) In the description of the simulation results, the eBayes and ShrinkBayes methods display very similar performance. The distinction between the results on the Figures is quite minimal. The authors should attempt to quantify the difference in performance in a single metric. For instance, in Figure 1, take the average percent difference in TPR across the FPRs that were used to generate the plot.}

\response{The area under the curve attempts to do exactly this, i.e. a single metric to compare the methods. We do not try to over-emphasize the difference between the ShrinkBayes and eBayes methods, which are both based on our model, as we do not believe there is much of a difference.}



Reviewer \#4

\comment{1. The authors propose a method to assess "gene expression heterosis."   While it is mentioned that this type of heterosis is a possible explanation for phenotypic heterosis, I'd like more discussion regarding this point.  The two references seem a bit outdated (for bioinformatics) so I'm wondering if this explanation is still being considered.  If it is, than I'd like to see more discussion about how the analytic results would be used to investigate this explanation.   Wouldn't scientists have specific phenotypic traits in mind and know of genes associated with these traits?  I'm a little confused why the search through the whole genome for this type of heterosis if they're looking to draw inference on the association.}

\response{We now include a reference to Chen (2013), a Nature Reviews Genetics article entitled ``Genomic and epigenetic insights into the molecular bases of heterosis'' as well as three other articles published in 2012 or later. Even though scientists may have specific candidates. An exploratory analysis to suggest other genes seems useful.} 

\comment{2. The model appears reasonable and is adapted from on used with microarrays.  To support their approach, they simulate data using their model (ideal case) and find that their approach does slightly better than ShrinkBayes.}

\response{We simulate data from the negative-binomial portion of the model, but do not simulate from the hierarchical portion of the model. Instead, we use edgeR estimates for gene-specific parameters which provide some shrinkage for the overdispersion parameters but none for the other gene-specific parameters. We have tried to make this clear in Section 3.1. In addition, we have performed the analysis by simulating entirely from our model and achieve similar results.}

\response{We also tried to emphasize in Section 2 that ``our'' approach includes the implementation in ShrinkBayes as the model itself is novel and eBayes and ShrinkBayes are just two different approaches to estimation.}

\comment{a. How robust do you feel your method is?  There is no discussion along these lines.}

\response{In the discussion, we mention the departures from model assumptions observed. Despite these violations, the results seems reasonable and thus suggest some level of robustness. We believe that further analysis of robustness is better left to future work specifically devoted to addressing this question.}

\comment{b.      Why is there more of an improvement over ShrinkBayes with more replicates?  Is it because of the method used to calculate the posterior probabilities?  I'd like to see some discussion on this.}

\response{We have added discussion in Section 3.3. This discussion points out the two main differences between ShrinkBayes and the eBayes approaches, but does not try to state which is the cause because, frankly, we don't know.}

\comment{c.      The ROC curves are not particularly impressive.  Even with 16 reps, the true positive rate is below 50\% (controlling for the false positive rate).  The real data example included only 4 reps, which is far more likely a scenario.  Very little discussion is devoted to this.}

\response{We have added discussion at the end of Section 3.1. The bottom line is that the ROC curves are not particularly impressive because we did not use artificially large signals, but we feel this is likely representative of real data.}

\comment{3.      Minor edits or comments}

\comment{a.      Start of Section 2 on page 2  :  Replace "We considering" with just "Consider"}

\response{Fixed.}

\comment{b.      Page 3: "The parental averages and overdispersion parameters are assumed to follow normal distributions, i.e.,"}

\response{Fixed.}

\comment{c.      Right before Section 2.2…it is assumed apriori independence, correct?}

\response{Yes, added \emph{a priori}.}

\comment{d.      Page 4: You have a two-step approach where you estimate the parameters of interest to get estimates of the hyperparameters and then restimate.  How much change is there is these estimates?  Why aren't the methods of McCarthy used as a competitor?}

\response{We have added a figure (Fig 3) to compare gene-specific parameter estimates and a paragraphing describing the comparison in Section 4. We aren't exactly sure which McCarthy methods you are referring to. We already use an approach based on edgeR and the point estimates themselves do not naturally lead to a statistic for determining the plausibility of heterosis.}

\comment{e.      Page 11 "These figures show marked departures from ……"}

\response{Fixed.}

\comment{f.      Page 11 : Does it really matter that the posterior is different from the prior?  One often assume aprior independence but expects there to be posterior correlation.  Perhaps I'm just missing something in this discussion.}

\response{Yes, we believe it does matter. Due to the nature of an empirical Bayes analysis, we only learn about the joint distribution of the gene-specific parameters through the hyperparameters, i.e. the gene-specific parameters will still be assumed to be independent and from the marginal distribution that was assumed (normal or Laplace). As an example, if the expression level ($\phi$) and overdispersion ($\psi$) parameters were assumed to have a bivariate normal distribution, then when inferring about $\psi$ we would use information about $\phi$, i.e. larger values of $\phi$ lead, on average, to smaller values for $\psi$. But this does not occur in the current model.}

\end{document}
